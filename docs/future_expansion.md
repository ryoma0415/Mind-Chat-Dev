# 将来的な機能拡張に関する考察

Mind-Chat を長期的に発展させるために検討している以下 3 項目について、現状の技術選定（Gemma 2 2B Japanese IT / llama.cpp / PySide6）や完全ローカルという制約を前提に、実現性と配布物サイズへの影響を整理します。

## 1. LangChain / LangGraph を活用した外部ナレッジ参照
- **実現性**:  
  - 現行の Python ベース構成とは親和性が高く、LangChain/LangGraph も純 Python ライブラリです。  
  - Gemma 2B は 4bit 量子化でも 2〜4 GB 程度の VRAM/メモリを要求するため、追加ワークフロー（RAG, ツール呼び出しなど）を組む際はリソース配分に注意が必要。  
  - ローカルのみで完結させるなら、Chroma/FAISS などのベクターストアを同梱し、ナレッジファイルを JSON / Markdown / PDF から抽出する処理が必要。
- **配布サイズへの影響**:  
  - LangChain/LangGraph 自体は 10〜20 MB 程度の Python ライブラリなので影響は小さい。  
  - ただし外部ナレッジ（例: 100 MB 程度のテキストやベクトル DB）を同梱すると、その分だけ PyInstaller 成果物が増える。  
  - ベクターストアをローカルで保持するなら 追加で 100〜500 MB 程度の増加を想定（ナレッジ量による）。

## 2. キャラクター UI / アニメーションの追加
- **実現性**:  
  - PySide6 は QWidget/QML の両方で画像・アニメーションの描画が可能。QMovie（GIF/WEBP）や QGraphicsView、Qt Quick を使えば簡易的なアニメーション表示は実装しやすい。  
  - 本格的な Live2D / 3D アバターは Qt 単体だと難しく、外部ランタイムや Unity/Unreal を組み込む必要があるため、ローカル単体アプリとしてはコストが高い。まずは PNG スプライトや MP4 ループ、QPropertyAnimation を組み合わせる案が現実的。
- **配布サイズ**:  
  - 静止画数枚であれば 1〜5 MB 程度の増加。  
  - 高解像度の動画/GIF を複数同梱すると 50〜200 MB 以上増える。  
  - Live2D モデル（モデルデータ＋モーション）は 100〜300 MB 程度になるケースもあるため、配布サイズとのトレードオフを要検討。

## 3. 音声入出力（音声認識 + キャラクターボイス）
- **実現性**:  
  - 入力: Vosk, Whisper.cpp, Faster-Whisper などローカル動作の ASR を利用可能。ただし GPU/CPU 負荷とモデルサイズ（300 MB〜1 GB）を許容できるかが鍵。  
  - 出力: 無料の TTS ライブラリ（e.g., Coqui TTS, Piper）をローカル推論させるか、商用 API を使わずに済ませる必要がある。キャラクターごとに声色を変えるには複数モデルやボイス変換が必要。  
  - PySide6 からは `PySide6.QtMultimedia` で音声再生が可能。録音は `sounddevice` や `pyaudio` を組み込む。
- **配布サイズ**:  
  - ASR/TTS のモデルサイズが最も大きく、1 モデル 300 MB〜1.5 GB 程度。複数キャラクターを用意すると数 GB 規模になる可能性がある。  
  - 音声ライブラリ自体は数 MB だが、エンジン + 各ボイスモデルをどこまで同梱するかで配布サイズが大きく変動する。  
  - PyInstaller でバンドルする場合、Gemma GGUF（約 2〜4 GB）に加えて TTS/ASR モデル群を含めると、配布物が 5 GB を超える恐れがある。インストーラ方式や差分ダウンロードを検討する余地がある。

## 推奨アプローチ
1. **LangChain/LangGraph**  
   - まずは軽量なテキスト・ベクターストアをローカルに配置し、チャット前に初期化する仕組みを設ける。  
   - 将来はプロジェクト開始時に「知識パック」フォルダを読み込む方式にすると、ユーザーが任意のナレッジを追加できる。
2. **UI 拡張**  
   - PySide6 での静的キャラクター表示→簡易アニメーション→QML/Qt Quick への移行という段階的なロードマップが現実的。  
   - 画像・動画素材を共通アセットフォルダにまとめて PyInstaller に取り込む。
3. **音声入出力**  
   - まずは軽量な音声認識／合成（例: Vosk small model, Piper small voice）でプロトタイプし、サイズや負荷を測定。  
   - キャラクターごとの声を求める場合は、ボイスモデルを差し替え可能な設計にする。ユーザーに追加ダウンロードさせる仕組み（アプリ内でモデルを選んで取得）も検討。

## まとめ
- 3案とも技術的には現行アーキテクチャで実装可能だが、モデルやアセットの容量増加がボトルネックになる。  
- 特に音声関連はモデルサイズの積み上がりが大きく、配布形態の再設計（インストーラ、差分ダウンロード、モジュール式パッケージなど）が必要。  
- 当面は LangChain ベースの機能強化や UI アセット追加など比較的軽量な改善から着手し、配布物サイズの実測値を得ながらステップアップしていくのが現実的。
